---
title: "Exploring impacts of reducing assessment frequency for BSAI Flathead Sole Complex"
author: "M Sosa Kapur maia.kapur@noaa.gov"
output:
  pdf_document:
    toc: no 
  html_notebook:
    theme: united
    toc: yes 
---
*Material presented in this document should not be considered final*.

In late May 2022 members of the SSMA were asked to produce runs producing ABC/OFLs for BSAI stocks "as if" assessment occurred only every 2 or 4 years. The BSAI FHS complex was  last fully assessed in 2020 by C Monnohan.  

This analysis uses the following assumptions and approaches: 

+ All runs are done using versions of the most recent benchmark assessment model conducted by C. Monnohan in 2020. This means that management quantities are products of that assessment model, and we would *not* expect them to exactly reproduce the values actually used for management in earlier years (since those assessments had different model configurations, and also had to estimate in-year catch data). Therefore, *values in this document should not be compared to those on the Federal Register*.

+ Relatedly, all simulated assessments in this analysis retained the parameterization from the 2020 model (i.e. no change to which parameters were estimated, nor the values at which they are fixed, both of which might affect model outcomes). The 2020 model was itself unchanged from 2018.

+ We focused on four- and two-year assessment intervals beginning in 2008. We ran a retrospective routine which truncates the data and the final year of model dynamics. This approach does *not* update (reverse) the terminal year of recruitment bias adjustment, which in 2020 was set at 2015.8. 

+ The `proj` model was used to get inter-benchmark reference points using the most recent benchmark model and the true observed catch from those years. For example, the four-year analysis conducts a full assessment in 2008, then an update assessment (`proj` model only) for years 2009-2011, here using true catch observations, before another full assessment in 2012. The two-year analysis would instead do a full assessment in 2010, which would be used in a `proj` model in 2011, etc.

+ The figures present one-year-ahead projections only, i.e. ABC/OFLs from the full assessment done in 2008 are shown for year 2009; values for 2010 come from the projection-only model from 2009, etc. 

+ Based on this quick analysis, there do not appear to be strong impacts in the period analyzed and given the assumptions at the beginning of this document. There are no changes in either management quantity (ABC or OFL) greater than 8%. At present, this accounts for roughly 5000 mt of catch; note that the average catch over the modeled period has been less than 10,000, while attainment (catch/TAC has been on the order of <25%.)

+ The realized TACs come from proj alternative #7.


```{r, eval = T, include = F, warning = FALSE, message = FALSE}
require(r4ss)
require(here)
require(tidyverse)
require(dplyr)
require(ggplot2)
theme_set(ggsidekick::theme_sleek())
```

```{r, eval = FALSE, include = FALSE, warning = FALSE, message = FALSE}
## from CCM
source(here('write_proj.r'))
source(here('write_proj_spcat.r')) # manually changed line 24 to not invoke data subdir
source(here('setup.r')) ## changed line 19 to turn off FMSY_35 as was done before
source(here('get_proj_res.r'))
## passed to write_proj function
NSEX=2						# number of sexes used in assessment model
Nfishery=1					# number of fisheries(fleets) #This was set equal to 2
fleets=1					# fleet index number (associated with commercial fishery)
rec_age=3					# assumed age at recruitment
max_age=21					# maximum age in model
NAGE=length(rec_age:max_age)			# number of ages
FY=1964 					# first year used to subset SSB
rec_FY=1964					# first year used to subset recruitment
rec_LY_decrement=0				# value subtracted from assessment final year to subset recruitment vector
spawn_month=1					# spawning month
Fratios=1            				# Proportion F per fishery
#passed to write_proj_spcat
ct_yrs=3			#Number of future catch years given to projection model
## passed to setup function
nsims=1000			# number of projection model simulations
nproj=14			# number of projection years ALSO USED BY get_proj_res
## passed to get_proj_res
spp="BSAI_flathead"

## Conduct a retrospective to get "full" assessments in 2 and 4 year increments
# SS_doRetro(masterdir = here('sos'),
#            oldsubdir = 'base_2020', ## copied from CCM 2020_files/model_runs/Run06_francis_tuning
#            ## 2008:2020 in two year increments
#            years = seq(0,-12,-2))

retrodirs <- list.dirs(here('retrospectives'), recursive = F)
# retromods <- SSgetoutput(dirvec = retrodirs)
# retroSummary <- SSsummarize(retromods)
# save(retroSummary, file = here('retrospectives',paste0(Sys.Date(),'-retroSummary.rdata')))
# retronames <- paste0('Full Assessment in ',seq(2008,2020,2))
# SSplotComparisons(retroSummary,
#                   plot = FALSE,
#                   png = T,
#                   endyrvec = seq(2008,2020,2),
#                   plotdir = here('retrospectives'),
#                   uncertainty=TRUE,  legendlabels = retronames)

## loop through all folders and generate a proj data file for each base model
lapply(retrodirs, FUN = function(x) write_proj(dir=x,  sdir =x,
                                               data_file="Model_Proj.dat", data=SS_output(x, verbose = F) ,
                                               NSEX=NSEX, NAGE=NAGE, Nfishery=Nfishery,
                                               fleets=fleets, rec_age=rec_age, max_age=max_age, FY=FY,
                                               rec_FY=rec_FY, rec_LY_decrement=rec_LY_decrement,
                                               spawn_month=spawn_month, Fratios=Fratios))

```
  

```{r, eval = FALSE, include = FALSE, warning = FALSE, message = FALSE}
## loop through retro folders and create projections at correct intervals
for(int in c(2,4)){
  master_table <- NULL; idx = 1 ## reset for each interval
  homedir = here(paste0('2022-05-11-proj-',int,'y')) ## premade folders
  # dir.create(homedir)
  ## copy in the relevant base models
  if(int ==2) { baseidx <-c(1:length(retrodirs))} else{ baseidx <- c(7,2,4,6)}
  baseYrs <- 2020+as.numeric(gsub('retro','',basename(retrodirs[baseidx]))) ## actual years, in order
  
  ## copy in all benchmark models at relevant intervals
  sapply(retrodirs[baseidx], FUN = function(x){
    fulldir = paste0(homedir, "/full-",2020+as.numeric(gsub('retro','',basename(x))))
    # dir.create(fulldir)
    # file.copy(from = list.files(x, full.names = T),  to=fulldir, overwrite = TRUE) ## includes model_proj
    # retro_base = SS_output(fulldir, verbose = F)
    # ## write spcat with year-specific catch info
    # write_proj_spcat(dir = fulldir,sdir = fulldir,
    #                  data_file = 'spp_catch.dat', ## name of new file - must match what is in spp_catch.dat
    #                  data =  retro_base, ## model basis
    #                  ct_yrs = int+1 ## eg for 2009 takes proj catch 2008-2012
    # )
    # 
    # ## write setup with year-specific catch info
    # setup(dir = fulldir, sdir = fulldir,
    #       data_file = 'setup.dat', ## name of new file 
    #       data = retro_base , ## model basis
    #       nproj = int+1
    # )
    # 
    #     ## copy executable and tacpar
    # file.copy(here('main.exe'), fulldir, overwrite = TRUE)
    # file.copy(here('tacpar.dat'), fulldir, overwrite = TRUE)
    # 
    # ## run proj for full year
    # setwd(fulldir) 
    # system('main.exe')
    
    # print(proj_out)
    this_year = 2020+as.numeric(gsub('retro','',basename(x)))
    rec_table1 <-
      read.table(paste0(fulldir,'/percentdb.out')) %>%
      as.data.frame(stringsAsFactors=FALSE) %>%
      transmute(scenario=as.numeric(V2), year=as.numeric(V3), metric=V4,
                value=as.numeric(V5)) %>%
      filter(      year >= this_year &
               metric %in% c('SSBMean','SSBFofl', 'SSBFabc', 'SSBF100', 'Fofl', 'Fabc')) %>%
      arrange(year, metric) %>%
      pivot_wider(names_from=year, values_from=value)
    rec_table1[3:6,3:ncol(rec_table1)] <- 1000*rec_table1[3:6,3:ncol(rec_table1)]
    rec_table2 <-
      read.table(paste0(fulldir,'/alt2_proj.out'), header=TRUE) %>%
      filter(      Year >= this_year )%>%
      pivot_longer(cols=c(-Stock, -Year), names_to='metric', values_to='value') %>%
      pivot_wider(names_from=Year, values_from=value)
    rec_table1$scenario <- rec_table2$Stock <- NULL
    rec_table2[,2:ncol(rec_table2)] <- 1000*rec_table2[,2:ncol(rec_table2)]
    rec_table <- bind_rows(rec_table1, rec_table2)
    TACS <- read.table(paste0(fulldir,'/means.out')) %>%
      as.data.frame(stringsAsFactors=FALSE) %>%
      transmute(scenario=as.numeric(V2), year=as.numeric(V3), metric=V4,
                value=as.numeric(V5))
    ## save individual rec table
    write.csv(rec_table, paste0(x,'/rec_table.csv'), row.names=FALSE)
    
    ## fill row for master table 
    nprojyrs = ncol(rec_table)-2 ## ignore "metric" and present year
    projyrvec = this_year+seq(1, nprojyrs)
    for(i in seq_along(projyrvec)){ 
      master_table$assessment_year[idx] = this_year
      master_table$assessment_type[idx] = "full"
      master_table$assessment_used[idx] = this_year
      master_table$refYr[idx] = projyrvec[i]
      ii <- which(names(rec_table) == as.character(projyrvec[i]))
      master_table$ABC[idx] = subset(rec_table,metric == 'ABC')[1,ii] %>% as.numeric()
      master_table$OFL[idx] = subset(rec_table,metric == 'OFL')[1,ii]%>% as.numeric()
      idx <<- idx+1 ## new row for each projection year
    }
    master_table <<- master_table ## global update within sapply
  })
  cat('finished copying full assessments and running proj ', int,"\n")
  ## copy in proj info at relevant intervals
  proj_years <- seq(2008,2020,1)[-(which(seq(2008,2020,1) %in% baseYrs))]
  proj_dirs <- paste0(homedir,"/proj-",  proj_years )
  sapply(proj_dirs , FUN = function(x){
    
    dir.create(x) ## make the projection folder
    projyr <- as.numeric(gsub('proj-','',basename(x)))
    ## bring in the model proj dat file (terminal year values from recent base model)
    ## this does not change between projection years
    yr_to_use <- paste0('full-',max(baseYrs[which(projyr>baseYrs)]))
    next_full_yr <- min(baseYrs[which(projyr<baseYrs)]) 
    base_to_use <- paste0(homedir,"/",yr_to_use) ## folder with most recent full assessment
    file.copy(paste0(base_to_use,"/model_proj.dat"), to=x, overwrite = TRUE)
    
    ## write spcat with year-specific catch info
    write_proj_spcat(dir = x,sdir = x,
                     data_file = 'spp_catch.dat', ## name of new file - must match what is in spp_catch.dat
                     data = SS_output(base_to_use, verbose = F) , ## model basis
                     ct_yrs = int+1 ## eg for 2009 takes proj catch 2008-2011
    )
    
    ## write setup with year-specific catch info
    setup(dir = x, sdir = x,
          data_file = 'setup.dat', ## name of new file - must match what is in spp_catch.dat
          data = SS_output(base_to_use, verbose = F) , ## model basis
          nproj = int+1
    )
    ## manually check: for projyr 2009:
    ## spp catch should have catch values 2008-2011
    ## model_proj should match full2008 (values thru 2008)
    
    ## copy executable and tacpar
    file.copy(here('main.exe'), x, overwrite = TRUE)
    file.copy(here('tacpar.dat'), x, overwrite = TRUE)
    
    ## run proj
    setwd(x) 
    system('main.exe')

    this_year = projyr
    rec_table1 <-
      read.table(paste0(x,'/percentdb.out')) %>%
      as.data.frame(stringsAsFactors=FALSE) %>%
      transmute(scenario=as.numeric(V2), year=as.numeric(V3), metric=V4,
                value=as.numeric(V5)) %>%
      filter(  year %in%  this_year:next_full_yr &
               scenario==1 &
               metric %in% c('SSBMean','SSBFofl', 'SSBFabc', 'SSBF100', 'Fofl', 'Fabc')) %>%
      arrange(year, metric) %>%
      pivot_wider(names_from=year, values_from=value)
    rec_table1[3:6,3:ncol(rec_table1)] <- 1000*rec_table1[3:6,3:ncol(rec_table1)]
    rec_table2 <-
      read.table(paste0(x,'/alt2_proj.out'), header=TRUE) %>%
      filter(Year %in% ( this_year:next_full_yr)) %>%
      pivot_longer(cols=c(-Stock, -Year), names_to='metric', values_to='value') %>%
      pivot_wider(names_from=Year, values_from=value)
    rec_table1$scenario <- rec_table2$Stock <- NULL
    rec_table2[,2:ncol(rec_table2)] <- 1000*rec_table2[,2:ncol(rec_table2)]
    rec_table <- bind_rows(rec_table1, rec_table2)
    
    ## save individual rec table
    write.csv(rec_table, paste0(x,'/rec_table.csv'), row.names=FALSE)
      ## fill row for master table 
    nprojyrs = ncol(rec_table)-2
    projyrvec = projyr:next_full_yr
    for(i in seq_along(projyrvec)){ 
      master_table$assessment_year[idx] = projyr
      master_table$assessment_type[idx] = "proj"
      master_table$assessment_used[idx] = baseYrs[which.min(baseYrs - projyr)]
      master_table$refYr[idx] = projyrvec[i]
      ii <- which(names(rec_table) == as.character(projyrvec[i]))
      master_table$ABC[idx] = subset(rec_table,metric == 'ABC')[1,ii] %>% as.numeric()
      master_table$OFL[idx] = subset(rec_table,metric == 'OFL')[1,ii]%>% as.numeric()
       idx <<- idx+1 ## new row for each projection year
    }
    
    nprojyrs = ncol(rec_table)-2 ## ignore "metric" and present year
    projyrvec = this_year+seq(1, nprojyrs)
    master_table <<- master_table ## global update within sapply
  }) ## end projection year sapply
  cat('ran proj for intermediate years ', int,"\n")
  master_table$interval = int
  master_table <- data.frame(master_table)
  write.csv(master_table, file = paste0(homedir, "/master_table.csv"),row.names = F)

} ## end loop over 2 or 4 year intervals
 


```


```{r, eval = T, echo = F, include = T, warning = FALSE, message = FALSE}

master_table <- bind_rows(read.csv(here('2022-05-11-proj-2y','master_table.csv'))  ,
                          read.csv(here('2022-05-11-proj-4y','master_table.csv'))  )
## plot results
  master_table2 <- master_table %>% 
    filter(refYr == assessment_year+1)  %>%## only use one year ahead
    reshape2::melt(id = names(master_table)[c(1:4,7)]) %>%
    mutate(value = value/1000) 

    ggplot(data = master_table2,
           aes(x = refYr, y = value, 
               group =    factor(assessment_type),
           col =  factor(assessment_type)))+
    theme(legend.position = 'top') +
      geom_point()+
    scale_x_continuous(limits = c(2008,2020),breaks = seq(2008,2020,2)) +
      scale_y_continuous(limits = c(0,100000))+
 
    scale_color_manual(values = c(alpha('goldenrod',0.8),alpha('blue',0.5),
                                  alpha('blue',0.8), alpha('goldenrod',0.5)),
    labels = c("Full Assessment", 'Update (proj only)')) +
    labs(x = 'Management Year', col = '',  y = '')  + 
    facet_grid(c("variable", "interval"), 
             labeller = "label_both", 
             scales = "free")
  
  # ggsave(last_plot(), file = paste0(homedir,"/refpts.png"),
  #        width =8, height = 6)
```

The percent change in ABCs and OFLs between frequencies are presented in the following table. Values are calculated as $\frac{OFL_{y, freq=4}-OFL_{y, freq=2}}{OFL_{y, freq=2}}$. 

```{r, eval = T, echo = F, include = T, warning = FALSE, message = FALSE}

master_table3 <- master_table2 %>% select(refYr, interval, variable, value) %>% pivot_wider(names_from = variable) 

merge(master_table3 %>% filter(interval == 2), master_table3 %>% filter(interval == 4), by = 'refYr') %>%
  mutate(ABC_pDiff =paste0(100*round(( ABC.y - ABC.x)/ABC.x,3),"%"),
         OFL_pDiff = paste0(100*round(( OFL.y - OFL.x)/OFL.x,3),"%")) %>%
  select(refYr, 
          "2 year ABC"= ABC.x ,
           "4 year ABC"= ABC.y ,
           "2 year OFL"= OFL.x ,
           "4 year OFL"= OFL.y ,
         ABC_pDiff, OFL_pDiff) %>%
  filter(refYr < 2020) 
```

